{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96607b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36694b4c",
   "metadata": {},
   "source": [
    "*A prediktáláshoz szükséges bementi featurek:*\n",
    "\n",
    "koi_period – keringési periódus (napokban).\n",
    "\n",
    "koi_time0bk / koi_time0 – az első tranzit kezdőidőpontja (BJD = Barycentric Julian Date).\n",
    "\n",
    "koi_eccen – excentricitás (pálya elliptikussága).\n",
    "\n",
    "koi_longp – periasztron hossztengelye.\n",
    "\n",
    "koi_impact – a tranzit ütközési paramétere (központi vagy széli áthaladás).\n",
    "\n",
    "koi_duration – a tranzit időtartama (órákban).\n",
    "\n",
    "koi_depth – a fényességcsökkenés mértéke ppm-ben (parts per million).\n",
    "\n",
    "koi_ror – a bolygó és a csillag sugarának aránya.\n",
    "\n",
    "koi_prad – bolygó sugara (Föld-sugarakban).\n",
    "\n",
    "koi_sma – fél nagytengely (csillag–bolygó távolság, csillag-sugarakban).\n",
    "\n",
    "koi_incl – inklináció (pályahajlás fokban).\n",
    "\n",
    "*Amire predikálunk:*\n",
    "\n",
    "koi_disposition – végső besorolás:\n",
    "\n",
    "CANDIDATE = bolygójelölt\n",
    "\n",
    "CONFIRMED = megerősített exobolygó\n",
    "\n",
    "FALSE POSITIVE = hamis találat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e25877fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(split: bool = False) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\Bence\\\\Documents\\\\Github\\\\NASA_SpaceApps_challenge_2025\\\\data\\\\kepler_KOI_full_dataset.csv\")\n",
    "    features = [\n",
    "        \"koi_period\",\n",
    "        \"koi_time0bk\",\n",
    "        \"koi_impact\",\n",
    "        \"koi_duration\",\n",
    "        \"koi_depth\",\n",
    "        \"koi_ror\",\n",
    "        \"koi_prad\",\n",
    "        \"koi_sma\",\n",
    "        \"koi_incls\",\n",
    "        \"koi_disposition\",\n",
    "    ]\n",
    "    df = df.filter(features)\n",
    "    df[\"koi_disposition\"] = np.where(df[\"koi_disposition\"] == \"CONFIRMED\", 1, 0)\n",
    "\n",
    "    if split:\n",
    "        y = df[\"koi_disposition\"]\n",
    "        X = df.drop(columns=[\"koi_disposition\"])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    return df\n",
    "\n",
    "def correlation_heatmap(df: pd.DataFrame) -> None:\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    sns.set(rc={\"figure.figsize\":(11.7,8.27)})\n",
    "\n",
    "def oversample_dataframe(df: pd.DataFrame, label_col: str) -> pd.DataFrame:\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X = df.drop(columns=[label_col])\n",
    "    y = df[label_col]\n",
    "    \n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    df_resampled[label_col] = y_resampled\n",
    "    return df_resampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def balanced_sampler(df: pd.DataFrame, label_col: str) -> pd.DataFrame:\n",
    "    grouped = df.groupby(label_col)\n",
    "    min_count = grouped.size().min()\n",
    "    \n",
    "    # Minden csoportból min_count darabot véletlenszerűen mintavételezünk\n",
    "    sampled = grouped.apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "    \n",
    "    # Az eredmény sorainak véletlenszerű összekeverése, hogy ne legyen blokkonként 0 vagy 1\n",
    "    shuffled = sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return shuffled\n",
    "\n",
    "def evaluate_random_forest(model, X_test, y_test, class_names=None, show_plot: bool = False) -> None:\n",
    "    # Predikciók\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Metrikák számítása\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    \n",
    "    # Kiírás\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=class_names))\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "    if show_plot:\n",
    "        # Confusion matrix kirajzolás\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        # ROC görbe kirajzolása ha lehetséges\n",
    "        if y_proba is not None:\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "            plt.figure(figsize=(6,5))\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curve')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77d72fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koi_disposition\n",
      "0    6818\n",
      "1    2746\n",
      "Name: count, dtype: int64\n",
      "   koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth   koi_ror  \\\n",
      "0    9.488036   170.538750       0.146       2.95750      615.8  0.022344   \n",
      "1   54.418383   162.513840       0.586       4.50700      874.8  0.027954   \n",
      "2   19.899140   175.850252       0.969       1.78220    10829.0  0.154046   \n",
      "3    1.736952   170.307565       1.276       2.40641     8079.2  0.387394   \n",
      "4    2.525592   171.595550       0.701       1.65450      603.3  0.024064   \n",
      "\n",
      "   koi_prad  koi_sma  koi_disposition  \n",
      "0      2.26   0.0853                1  \n",
      "1      2.83   0.2734                1  \n",
      "2     14.60   0.1419                0  \n",
      "3     33.46   0.0267                0  \n",
      "4      2.75   0.0374                1  \n"
     ]
    }
   ],
   "source": [
    "df = load_dataset()\n",
    "#correlation_heatmap(df)\n",
    "print(df[\"koi_disposition\"].value_counts())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd256bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.87      0.91      0.89      1344\n",
      "     CONFIRMED       0.77      0.67      0.71       569\n",
      "\n",
      "      accuracy                           0.84      1913\n",
      "     macro avg       0.82      0.79      0.80      1913\n",
      "  weighted avg       0.84      0.84      0.84      1913\n",
      "\n",
      "Accuracy: 0.8400\n",
      "Precision: 0.7657\n",
      "Recall: 0.6661\n",
      "F1 Score: 0.7124\n",
      "ROC AUC Score: 0.9156\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset(split=True)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_random_forest(model, X_test, y_test, class_names=[\"FALSE POSITIVE\", \"CONFIRMED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bad89ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bence\\AppData\\Local\\Temp\\ipykernel_9020\\1731462826.py:46: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled = grouped.apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.87      0.79      0.82       547\n",
      "     CONFIRMED       0.81      0.88      0.84       552\n",
      "\n",
      "      accuracy                           0.83      1099\n",
      "     macro avg       0.84      0.83      0.83      1099\n",
      "  weighted avg       0.84      0.83      0.83      1099\n",
      "\n",
      "Accuracy: 0.8335\n",
      "Precision: 0.8060\n",
      "Recall: 0.8804\n",
      "F1 Score: 0.8416\n",
      "ROC AUC Score: 0.9162\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset()\n",
    "df = balanced_sampler(df=df, label_col=\"koi_disposition\")\n",
    "y = df[\"koi_disposition\"]\n",
    "X = df.drop(columns=[\"koi_disposition\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_random_forest(model, X_test, y_test, class_names=[\"FALSE POSITIVE\", \"CONFIRMED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "550f2c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.97      0.89      0.93      1378\n",
      "     CONFIRMED       0.90      0.97      0.93      1350\n",
      "\n",
      "      accuracy                           0.93      2728\n",
      "     macro avg       0.93      0.93      0.93      2728\n",
      "  weighted avg       0.93      0.93      0.93      2728\n",
      "\n",
      "Accuracy: 0.9322\n",
      "Precision: 0.9003\n",
      "Recall: 0.9704\n",
      "F1 Score: 0.9340\n",
      "ROC AUC Score: 0.9837\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset()\n",
    "df = oversample_dataframe(df=df, label_col=\"koi_disposition\")\n",
    "y = df[\"koi_disposition\"]\n",
    "X = df.drop(columns=[\"koi_disposition\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_random_forest(model, X_test, y_test, class_names=[\"FALSE POSITIVE\", \"CONFIRMED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c92c21a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.87      0.90      0.89      1344\n",
      "     CONFIRMED       0.74      0.69      0.72       569\n",
      "\n",
      "      accuracy                           0.84      1913\n",
      "     macro avg       0.81      0.79      0.80      1913\n",
      "  weighted avg       0.83      0.84      0.83      1913\n",
      "\n",
      "Accuracy: 0.8364\n",
      "Precision: 0.7406\n",
      "Recall: 0.6924\n",
      "F1 Score: 0.7157\n",
      "ROC AUC Score: 0.9127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bence\\Documents\\Github\\NASA_SpaceApps_challenge_2025\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:26:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_dataset(split=True)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_random_forest(model, X_test, y_test, class_names=[\"FALSE POSITIVE\", \"CONFIRMED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "876d3d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.87      0.79      0.83       547\n",
      "     CONFIRMED       0.81      0.88      0.85       552\n",
      "\n",
      "      accuracy                           0.84      1099\n",
      "     macro avg       0.84      0.84      0.84      1099\n",
      "  weighted avg       0.84      0.84      0.84      1099\n",
      "\n",
      "Accuracy: 0.8380\n",
      "Precision: 0.8106\n",
      "Recall: 0.8841\n",
      "F1 Score: 0.8458\n",
      "ROC AUC Score: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bence\\AppData\\Local\\Temp\\ipykernel_9020\\1731462826.py:46: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled = grouped.apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
      "c:\\Users\\Bence\\Documents\\Github\\NASA_SpaceApps_challenge_2025\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [15:26:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset()\n",
    "df = balanced_sampler(df=df, label_col=\"koi_disposition\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[\"koi_disposition\"]), df[\"koi_disposition\"], test_size=0.2, random_state=42)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_random_forest(model, X_test, y_test, class_names=[\"FALSE POSITIVE\", \"CONFIRMED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf4520",
   "metadata": {},
   "source": [
    "Buckle up for this rage induced down spiraling shit tornado called deep learning\n",
    "\n",
    "*yeeeeehaaaw*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de535de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    trigger_times = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                outputs = model(X_val).squeeze()\n",
    "                val_loss += criterion(outputs, y_val).item()\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            trigger_times = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            trigger_times += 1\n",
    "            if trigger_times >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset()\n",
    "df = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Modell létrehozása és tanítás\n",
    "model = MLP(input_dim=8)\n",
    "train_model(model, train_loader, val_loader, epochs=50, lr=0.001)\n",
    "\n",
    "# Betöltés a legjobb modell\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
